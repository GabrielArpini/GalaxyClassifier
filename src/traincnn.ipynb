{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "elWlDaflih7M"
   },
   "outputs": [],
   "source": [
    "!pip install astroNN --quiet\n",
    "!pip install torchmetrics --quiet\n",
    "!pip install scikit-image --quiet\n",
    "!pip install mlflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "y6gS1F2kioNm",
    "outputId": "53bb3bc6-1fc6-4d57-f63e-bfd9867fcab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cu126'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from utils.focal_loss import FocalLoss\n",
    "import utils.general as g\n",
    "from cnn import NeuralNet\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astroNN.datasets import load_galaxy10\n",
    "\n",
    "import skimage as ski\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gh-esmTjQXB",
    "outputId": "6b3877a5-24bf-448e-df47-e59a7d005179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "euYz6RfyjSoa"
   },
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"0 - Disturbed Galaxies\",\n",
    "    \"1 - Merging Galaxies\",\n",
    "    \"2 - Round Smooth Galaxies\",\n",
    "    \"3 - In-between Round Smooth Galaxies\",\n",
    "    \"4 - Cigar Shaped Smooth Galaxies\",\n",
    "    \"5 - Barred Spiral Galaxies\",\n",
    "    \"6 - Unbarred Tight Spiral Galaxies\",\n",
    "    \"7 - Unbarred Loose Spiral Galaxies\",\n",
    "    \"8 - Edge-on Galaxies without Bulge\",\n",
    "    \"9 - Edge-on Galaxies with Bulge\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arpoca/GalaxyClassifier/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "s3RK4QGcjWkk"
   },
   "outputs": [],
   "source": [
    "images,labels = g.get_data('/home/arpoca/GalaxyClassifier/src/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YloVCmT7jXUK"
   },
   "outputs": [],
   "source": [
    "def get_label_count(labels):\n",
    "  counts = np.unique(labels, return_counts=True)\n",
    "  return counts[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4z6uuVZj3ee",
    "outputId": "4353b8c1-9b74-45ba-80bf-559e901f25de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: Counter({np.uint8(2): 1587, np.uint8(7): 1577, np.uint8(5): 1226, np.uint8(3): 1216, np.uint8(9): 1124, np.uint8(1): 1112, np.uint8(6): 1097, np.uint8(8): 854, np.uint8(0): 648, np.uint8(4): 200})\n",
      "Valid distribution: Counter({np.uint8(2): 529, np.uint8(7): 525, np.uint8(5): 408, np.uint8(3): 405, np.uint8(9): 374, np.uint8(1): 371, np.uint8(6): 366, np.uint8(8): 285, np.uint8(0): 217, np.uint8(4): 67})\n",
      "Test distribution: Counter({np.uint8(2): 529, np.uint8(7): 526, np.uint8(5): 409, np.uint8(3): 406, np.uint8(9): 375, np.uint8(1): 370, np.uint8(6): 366, np.uint8(8): 284, np.uint8(0): 216, np.uint8(4): 67})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels, test_size=0.4, stratify=labels, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "X_temp = None\n",
    "y_temp = None\n",
    "\n",
    "# Verify splits\n",
    "print(f\"Train distribution: {Counter(y_train)}\")\n",
    "print(f\"Valid distribution: {Counter(y_val)}\")\n",
    "print(f\"Test distribution: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "aA1vLlIFnp6L"
   },
   "outputs": [],
   "source": [
    "num_samples_per_class = get_label_count(y_train)\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rclB7E7RkJpr"
   },
   "outputs": [],
   "source": [
    "images_path = '/home/arpoca/GalaxyClassifier/src/data/images.npy'\n",
    "labels_path = '/home/arpoca/GalaxyClassifier/src/data/labels.npy'\n",
    "train_dataset, test_dataset, valid_dataset = g.get_dataset(X_train, X_test, X_val,images_path,labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Yg-hRZFQk7uJ"
   },
   "outputs": [],
   "source": [
    "X_train = y_train = X_test = y_test = X_val = y_val = images = labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "S0aMSBcGlZ9j"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "4wJUfxWTmqTy"
   },
   "outputs": [],
   "source": [
    "model = NeuralNet().to(device)\n",
    "fl = FocalLoss(\n",
    "    beta=0.999,\n",
    "    gamma=2.0,\n",
    "    samples_per_class=num_samples_per_class,\n",
    "    reduce=True\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(list(class_weight_dict.values()))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "yZlHPHHhn_a5"
   },
   "outputs": [],
   "source": [
    "def train_book(model, optimizer, criterion, train_loader, n_epochs, device):\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch).to(device)\n",
    "\n",
    "            # Ensure y_batch is integer indices\n",
    "            if y_batch.dtype != torch.long:\n",
    "                y_batch = y_batch.long()\n",
    "\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        accuracy.reset()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in valid_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                _, predicted_class = torch.max(y_pred, 1)  # Get predicted class indices\n",
    "                accuracy.update(predicted_class, y_batch)  # Use y_batch directly (integer indices)\n",
    "\n",
    "        final_accuracy = accuracy.compute()\n",
    "        with torch.no_grad():\n",
    "            all_predictions = []\n",
    "            for X_batch, y_batch in valid_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                _, predicted_class = torch.max(y_pred, 1)\n",
    "                all_predictions.extend(predicted_class.cpu().numpy())\n",
    "        pred_distribution = Counter(all_predictions)\n",
    "        print(f\"Predicted class distribution: {pred_distribution}\")\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}, Validation Accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "zd9FeM-XoD3w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class distribution: Counter({np.int64(2): 1521, np.int64(5): 1490, np.int64(3): 474, np.int64(4): 48, np.int64(1): 8, np.int64(0): 6})\n",
      "Epoch 1/10, Loss: 1.1575, Validation Accuracy: 0.1142\n",
      "Predicted class distribution: Counter({np.int64(5): 1022, np.int64(3): 965, np.int64(1): 859, np.int64(2): 576, np.int64(0): 125})\n",
      "Epoch 2/10, Loss: 0.9756, Validation Accuracy: 0.2856\n",
      "Predicted class distribution: Counter({np.int64(2): 1568, np.int64(1): 836, np.int64(0): 595, np.int64(5): 275, np.int64(3): 141, np.int64(4): 74, np.int64(6): 58})\n",
      "Epoch 3/10, Loss: 0.8927, Validation Accuracy: 0.4590\n",
      "Predicted class distribution: Counter({np.int64(5): 1615, np.int64(1): 1266, np.int64(4): 231, np.int64(2): 203, np.int64(3): 130, np.int64(0): 90, np.int64(6): 12})\n",
      "Epoch 4/10, Loss: 0.8365, Validation Accuracy: 0.3039\n",
      "Predicted class distribution: Counter({np.int64(0): 904, np.int64(1): 732, np.int64(5): 652, np.int64(3): 467, np.int64(2): 399, np.int64(4): 368, np.int64(6): 25})\n",
      "Epoch 5/10, Loss: 0.7452, Validation Accuracy: 0.4218\n",
      "Predicted class distribution: Counter({np.int64(1): 1515, np.int64(0): 675, np.int64(2): 583, np.int64(3): 423, np.int64(5): 282, np.int64(4): 46, np.int64(6): 23})\n",
      "Epoch 6/10, Loss: 0.6621, Validation Accuracy: 0.6400\n",
      "Predicted class distribution: Counter({np.int64(1): 1677, np.int64(3): 698, np.int64(5): 434, np.int64(2): 360, np.int64(0): 253, np.int64(6): 65, np.int64(4): 60})\n",
      "Epoch 7/10, Loss: 0.5757, Validation Accuracy: 0.5799\n",
      "Predicted class distribution: Counter({np.int64(1): 1444, np.int64(2): 909, np.int64(0): 467, np.int64(3): 316, np.int64(5): 232, np.int64(4): 171, np.int64(6): 8})\n",
      "Epoch 8/10, Loss: 0.5164, Validation Accuracy: 0.6704\n",
      "Predicted class distribution: Counter({np.int64(1): 1401, np.int64(2): 982, np.int64(3): 422, np.int64(5): 413, np.int64(0): 218, np.int64(4): 111})\n",
      "Epoch 9/10, Loss: 0.4474, Validation Accuracy: 0.5861\n",
      "Predicted class distribution: Counter({np.int64(1): 1775, np.int64(2): 722, np.int64(0): 691, np.int64(3): 206, np.int64(5): 129, np.int64(4): 21, np.int64(6): 3})\n",
      "Epoch 10/10, Loss: 0.3897, Validation Accuracy: 0.8325\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=.15)\n",
    "train_book(model, optimizer, fl, train_loader, n_epochs=10,device=device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "YT7rCwpjqwOK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for 0 - Disturbed Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 1 - Merging Galaxies:\n",
      "  Precision: 0.5206\n",
      "  Recall: 0.9892\n",
      "  F1-score: 0.6822\n",
      "Metrics for 2 - Round Smooth Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 3 - In-between Round Smooth Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 4 - Cigar Shaped Smooth Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 5 - Barred Spiral Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 6 - Unbarred Tight Spiral Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 7 - Unbarred Loose Spiral Galaxies:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 8 - Edge-on Galaxies without Bulge:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n",
      "Metrics for 9 - Edge-on Galaxies with Bulge:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "metric = torchmetrics.classification.MulticlassConfusionMatrix(num_classes=10).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_logits = model(X_batch)  # Raw logits [batch_size, 10]\n",
    "\n",
    "        # Convert logits to predicted class indices\n",
    "        _, y_pred_classes = torch.max(y_pred_logits, 1)\n",
    "\n",
    "        metric.update(y_pred_classes, y_batch)  # Now using class indices, not logits\n",
    "\n",
    "conf_matrix = metric.compute()\n",
    "\n",
    "# Calculate precision, recall, and F1-score from the confusion matrix\n",
    "for i, class_name in enumerate(class_names):\n",
    "    tp = conf_matrix[i, i].item()\n",
    "    fp = conf_matrix[:, i].sum().item() - tp\n",
    "    fn = conf_matrix[i, :].sum().item() - tp\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f\"Metrics for {class_name}:\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "giO-hkzQxpjv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING EVALUATION ===\n",
      "EVALUATION - Predicted distribution: Counter({np.int64(1): 3520, np.int64(5): 27})\n",
      "EVALUATION - Target distribution: Counter({np.int64(1): 1853, np.int64(0): 1081, np.int64(2): 613})\n",
      "Confusion matrix shape: torch.Size([10, 10])\n",
      "Confusion matrix:\n",
      "tensor([[   0, 1076,    0,    0,    0,    5,    0,    0,    0,    0],\n",
      "        [   0, 1833,    0,    0,    0,   20,    0,    0,    0,    0],\n",
      "        [   0,  611,    0,    0,    0,    2,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DEBUGGING EVALUATION ===\")\n",
    "model.eval()\n",
    "\n",
    "# Check what the model actually predicts during evaluation\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in valid_loader:  # Use the SAME loader as training\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_logits = model(X_batch)\n",
    "        _, y_pred_classes = torch.max(y_pred_logits, 1)\n",
    "\n",
    "        all_preds.extend(y_pred_classes.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "from collections import Counter\n",
    "print(f\"EVALUATION - Predicted distribution: {Counter(all_preds)}\")\n",
    "print(f\"EVALUATION - Target distribution: {Counter(all_targets)}\")\n",
    "\n",
    "# Now run your confusion matrix code\n",
    "metric = torchmetrics.classification.MulticlassConfusionMatrix(num_classes=10).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in valid_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_logits = model(X_batch)\n",
    "        _, y_pred_classes = torch.max(y_pred_logits, 1)\n",
    "        metric.update(y_pred_classes, y_batch)\n",
    "\n",
    "conf_matrix = metric.compute()\n",
    "print(f\"Confusion matrix shape: {conf_matrix.shape}\")\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "E37JOyepKk_X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
